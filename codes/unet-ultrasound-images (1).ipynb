{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nfrom cv2 import imread, createCLAHE \nimport cv2\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom numpy import savez_compressed\nimport matplotlib.pyplot as plt \nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom os import listdir\nfrom numpy import asarray\n\nfrom pydicom import dcmread\n\nimport glob \nfrom os import listdir\nfrom numpy import asarray\nfrom numpy import vstack\n\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nimport numpy as np \n\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import load\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import LeakyReLU\nfrom matplotlib import pyplot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = os.path.join(\"../input/unetdata/testing_256.npz\")\ntraining = os.path.join(\"../input/input/unetdata/training_256.npz\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotMask(X,y):\n    sample = []\n    \n    for i in range(6):\n        left = X[i]\n        right = y[i]\n        combined = np.hstack((left,right))\n        sample.append(combined)\n        \n        \n    for i in range(0,6,3):\n\n        plt.figure(figsize=(25,10))\n        \n        plt.subplot(2,3,1+i)\n        plt.imshow(sample[i].astype('uint8'))\n        \n        plt.subplot(2,3,2+i)\n        plt.imshow(sample[i+1].astype('uint8'))\n        \n        \n        plt.subplot(2,3,3+i)\n        plt.imshow(sample[i+2].astype('uint8'))\n        \n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# plot training and testing images ","metadata":{}},{"cell_type":"code","source":"# Load training and testing data\ndatatrain = load(\"../input/unetdata/training_256.npz\")\nX_train, y_train = datatrain['arr_0'], datatrain['arr_1']\nplotMask(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datatest = load(\"../input/unetdata/testing_256.npz\")\nX_test, y_test = datatest['arr_0'], datatest['arr_1']\nplotMask(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert X_train.shape == y_train.shape\nassert X_test.shape == y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nassert X_train.shape == y_train.shape\nassert X_test.shape == y_test.shape\nimages = np.concatenate((X_train,X_test),axis=0)\nmask  = np.concatenate((y_train,y_test),axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras import backend as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', dtype='float32')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(3, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet(input_size=(256,256,3))\nmodel.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss,\n                  metrics=[dice_coef, 'binary_accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                                   patience=3,\n                                   verbose=1, mode='min', epsilon=0.0002, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import clear_output\nfrom tensorflow.keras.optimizers import Adam \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nmodel.compile(optimizer=Adam(lr=0.00001), \n              loss=[dice_coef_loss], \n           metrics = [dice_coef, 'binary_accuracy', 'AUC'])\n\ntrain_vol, validation_vol, train_seg, validation_seg = train_test_split((images)/255, \n                                                            (mask>127).astype(np.float32), \n                                                            test_size = 0.1,random_state = 2018)\n\ntrain_vol, test_vol, train_seg, test_seg = train_test_split(train_vol,train_seg, \n                                                            test_size = 0.1, \n                                                            random_state = 2018)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test_vol[0].astype(np.float32))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = model.fit(x = train_vol,\n                       y = train_seg,\n                         batch_size = 8,\n                  epochs = 120,\n                  validation_data =(test_vol,test_seg) ,\n                  callbacks=callbacks_list)\n\nmodel.save('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.plot(loss_history.history['loss'], '-', label = 'Loss')\nax1.plot(loss_history.history['val_loss'], '-', label = 'Validation Loss')\nax1.legend()\n\nax2.plot(100*np.array(loss_history.history['binary_accuracy']), '-', \n         label = 'Accuracy')\nax2.plot(100*np.array(loss_history.history['val_binary_accuracy']), '-',\n         label = 'Validation Accuracy')\nax2.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(loss_history.history['loss'], '-', label = 'Loss')\nplt.plot(loss_history.history['val_loss'], '-', label = 'Validation Loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Dice Loss')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(loss_history.history['auc'], '-', label = 'AUC')\nplt.plot(loss_history.history['val_auc'], '-', label = 'Validation AUC')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('AUC')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_candidates = np.random.randint(1,validation_vol.shape[0],10)\npreds = model.predict(validation_vol)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vol.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs = model.predict(test_vol)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_candidates","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(preds[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.figure(figsize=(20,10))\n\nfor i in range(0,9,4):\n    plt.subplot(4,4,i+1)\n    \n    plt.imshow(validation_vol[pred_candidates[i]].astype(np.float32))\n    plt.xlabel(\"Base Image\")\n    plt.axis('off')\n    \n    \n    plt.subplot(4,4,i+2)\n    plt.imshow(np.squeeze(validation_seg[pred_candidates[i]]).astype(np.float32))\n    plt.xlabel(\"Mask\")\n    plt.axis('off')\n    \n    plt.subplot(4,4,i+3)\n    plt.imshow(np.squeeze(preds[pred_candidates[i]]).astype(np.float32))\n    plt.xlabel(\"Pridiction\")\n    plt.axis('off')\n    \n    plt.subplot(4,4,i+4)\n    plt.imshow(validation_vol[pred_candidates[i]]+np.squeeze(preds[pred_candidates[i]]*0.2).astype(np.float32))\n    plt.xlabel(\"Pridiction\")\n    plt.axis('off')\n    \n    plt.tight_layout()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom numpy import load\nfrom numpy import vstack\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom numpy.random import randint\nimport tensorflow.keras as tf\n# load and prepare training images\ndef load_real_samples(filename):\n    # load compressed arrays\n    data = load(filename)\n    # unpack arrays\n    X1, X2 = data['arr_0'], data['arr_1']\n    # scale from [0,255] to [-1,1]\n    X1 = ((X1) / 255.0)\n    X2 = ((X2) / 255.0)\n    return [X1, X2]\nssi = []\npsi = []\niou = []\n# plot source, generated and target images\ndef plot_images(src_img, gen_img, tar_img):\n    images = vstack((src_img, gen_img, tar_img))\n    # scale from [-1,1] to [0,1]\n    images = (images + 1) / 2.0\n    titles = ['Source', 'Generated', 'Expected']\n    # plot images row by row\n    fig = plt.figure(figsize = [8,8])\n    for i in range(len(images)):\n        # define subplot\n        ax = pyplot.subplot(1, 3, 1 + i)\n        #plt.figure(figsize = [5,5])\n        # turn off axis\n        pyplot.axis('off')\n        # plot raw pixel data\n        ax.imshow(np.squeeze(images[i]).astype(np.float32), cmap = 'gray')\n        # show title\n        ax.set_title(titles[i])\n    ss = str(float(ssim1))\n    ps = str(float(psnr1))\n    io = str(float(iou1))\n    \n    a =  'SSIM:' ,ss[:5], 'PSNR:' ,  ps[:5], 'IOU=', io[:5]\n    print(a)\n    \n    ssi.append(ss)\n    psi.append(ps)\n    iou.append(io)\n    fig.suptitle(a)\n    fig.tight_layout()\n    fig.subplots_adjust(top= 1.5)\n    #plt.savefig(name, bbox_inches = 'tight', pad_inches = 0)\n    \n    pyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \n#tf.random.Generator = None  # Patch for a bug\nfrom tensorflow_addons.layers import InstanceNormalization\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# for testing images","metadata":{}},{"cell_type":"code","source":"[X2, X1] = load_real_samples('../input/unetdata/testing_256.npz')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[X2, X1] = load_real_samples('../input/unetdata/testing_256.npz')\n#print('Loaded', X1.shape, X2.shape)\n# load model\n\n\nimport numpy as np \nXD = np.arange(0,65)\nfor i in range(20):\n    print('for image number ', i )\n    name = 'mname'+ '_'+str(i) +'_' + '.png'\n\n    ix = XD[i]\n    ix = np.array([ix])\n    tar_image, src_image   = X1[[ix]], X2[[ix]]\n    # generate image from source\n    gen_image = model.predict(src_image)\n    # plot all three images\n    images = vstack((src_image, gen_image, tar_image))\n    images = (images + 1) / 2.0\n    df = images[1]\n\n    print('RAW image: ', 'Min: %.3f, Max: %.3f' % (df.min(), df.max()))\n    df1 = ((df) / df.max())*255\n    print('After rescaling: Min: %.3f, Max: %.3f' % (df1.min(), df1.max()))\n    dfn = images[2]\n\n    print('RAW image: ', 'Min: %.3f, Max: %.3f' % (dfn.min(), dfn.max()))\n    dfn1 = ((dfn) / dfn.max())*255\n    print('After rescaling: Min: %.3f, Max: %.3f' % (dfn1.min(), dfn1.max()))\n\n    a =tf.convert_to_tensor(df1, tf.uint8)\n    b = tf.convert_to_tensor(dfn1, tf.uint8)\n    ssim1 = tf.image.ssim(a,b, max_val=255, filter_size=11,filter_sigma=1.5, k1=0.01, k2=0.03) \n    psnr1 = tf.image.psnr(a, b, max_val=255)\n    print(float(ssim1))\n    print(float(psnr1))\n    im1 = tf.image.convert_image_dtype(a, tf.float32)\n    im2 = tf.image.convert_image_dtype(b, tf.float32)\n    ssim2 = tf.image.ssim(im1,im2, max_val=1, filter_size=11,\n                          filter_sigma=1.5, k1=0.01, k2=0.03)\n    # IOU calculation \n    a1 = a[:,:,0]\n    img = a1/np.max(a1)\n    imgn = np.where(img<0.9,0, 1)\n\n    #plt.imshow(imgn, cmap = 'gray')\n\n    b1 = b[:,:,0]\n    imgb = b1/np.max(b1)\n    imgb = np.where(imgb<0.9,0, 1)\n    #plt.imshow(imgb, cmap = 'gray')\n\n    m = tf.keras.metrics.MeanIoU(num_classes=2)\n    m.update_state(imgn, imgb)\n    iou1 = m.result().numpy()\n    plot_images(src_image, gen_image, tar_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iou1 = []\nssim1 = []\nPSNR = []\nfor i in range(len(iou)):\n    iou1.append(float(iou[i]))\n    ssim1.append(float(ssi[i]))\n    PSNR.append(float(psi[i]))\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\nplt.plot(iou1)\nplt.ylabel('IOU')\nplt.xlabel('Image id')\nplt.show()\nplt.plot(ssim1)\nplt.ylabel('SSIM')\nplt.xlabel('Image id')\nplt.show()\nplt.plot(PSNR)\nplt.ylabel('PSNR')\nplt.xlabel('Image id')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nprint('mean iou: ', np.mean(iou1))\nprint('mean SSIM: ', np.mean(ssim1))\nprint('mean PSNR: ', np.mean(PSNR))\nprint('mean iou: ', np.std(iou1))\nprint('mean SSIM: ', np.std(ssim1))\nprint('mean PSNR: ', np.std(PSNR))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = (pd.DataFrame([iou1, ssim1, PSNR])).transpose()\ndf.columns = ['iou', 'ssim', 'PSNR']\ndf.to_csv('valid.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# for training dataset ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom numpy import load\nfrom numpy import vstack\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom numpy.random import randint\nimport tensorflow.keras as tf\n# load and prepare training images\ndef load_real_samples(filename):\n    # load compressed arrays\n    data = load(filename)\n    # unpack arrays\n    X1, X2 = data['arr_0'], data['arr_1']\n    # scale from [0,255] to [-1,1]\n    X1 = ((X1) / 255.0)\n    X2 = ((X2) / 255.0)\n    return [X1, X2]\nssi = []\npsi = []\niou = []\n# plot source, generated and target images\ndef plot_images(src_img, gen_img, tar_img):\n    images = vstack((src_img, gen_img, tar_img))\n    # scale from [-1,1] to [0,1]\n    images = (images + 1) / 2.0\n    titles = ['Source', 'Generated', 'Expected']\n    # plot images row by row\n    #fig = plt.figure(figsize = [8,8])\n    #for i in range(len(images)):\n        # define subplot\n        #ax = pyplot.subplot(1, 3, 1 + i)\n        #plt.figure(figsize = [5,5])\n        # turn off axis\n        #pyplot.axis('off')\n        # plot raw pixel data\n        #ax.imshow(np.squeeze(images[i]).astype(np.float32), cmap = 'gray')\n        # show title\n        #ax.set_title(titles[i])\n    ss = str(float(ssim1))\n    ps = str(float(psnr1))\n    io = str(float(iou1))\n    \n    a =  'SSIM:' ,ss[:5], 'PSNR:' ,  ps[:5], 'IOU=', io[:5]\n    print(a)\n    \n    ssi.append(ss)\n    psi.append(ps)\n    iou.append(io)\n    #fig.suptitle(a)\n    #fig.tight_layout()\n    #fig.subplots_adjust(top= 1.5)\n    #plt.savefig(name, bbox_inches = 'tight', pad_inches = 0)\n    \n    pyplot.show()\n    \nimport tensorflow as tf \n#tf.random.Generator = None  # Patch for a bug\nfrom tensorflow_addons.layers import InstanceNormalization","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \n#tf.random.Generator = None  # Patch for a bug\nfrom tensorflow_addons.layers import InstanceNormalization\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[X2, X1] = load_real_samples('../input/unetdata/training_256.npz')\n#print('Loaded', X1.shape, X2.shape)\n# load model\n\n\nimport numpy as np \nXD = np.arange(0,555-20)\nfor i in range(555-20):\n    print('for image number ', i )\n    name = 'mname'+ '_'+str(i) +'_' + '.png'\n\n    ix = XD[i]\n    ix = np.array([ix])\n    tar_image, src_image   = X1[[ix]], X2[[ix]]\n    # generate image from source\n    gen_image = model.predict(src_image)\n    # plot all three images\n    images = vstack((src_image, gen_image, tar_image))\n    images = (images + 1) / 2.0\n    df = images[1]\n\n    print('RAW image: ', 'Min: %.3f, Max: %.3f' % (df.min(), df.max()))\n    df1 = ((df) / df.max())*255\n    print('After rescaling: Min: %.3f, Max: %.3f' % (df1.min(), df1.max()))\n    dfn = images[2]\n\n    print('RAW image: ', 'Min: %.3f, Max: %.3f' % (dfn.min(), dfn.max()))\n    dfn1 = ((dfn) / dfn.max())*255\n    print('After rescaling: Min: %.3f, Max: %.3f' % (dfn1.min(), dfn1.max()))\n\n    a =tf.convert_to_tensor(df1, tf.uint8)\n    b = tf.convert_to_tensor(dfn1, tf.uint8)\n    ssim1 = tf.image.ssim(a,b, max_val=255, filter_size=11,filter_sigma=1.5, k1=0.01, k2=0.03) \n    psnr1 = tf.image.psnr(a, b, max_val=255)\n    print(float(ssim1))\n    print(float(psnr1))\n    im1 = tf.image.convert_image_dtype(a, tf.float32)\n    im2 = tf.image.convert_image_dtype(b, tf.float32)\n    ssim2 = tf.image.ssim(im1,im2, max_val=1, filter_size=11,\n                          filter_sigma=1.5, k1=0.01, k2=0.03)\n    # IOU calculation \n    a1 = a[:,:,0]\n    img = a1/np.max(a1)\n    imgn = np.where(img<0.9,0, 1)\n\n    #plt.imshow(imgn, cmap = 'gray')\n\n    b1 = b[:,:,0]\n    imgb = b1/np.max(b1)\n    imgb = np.where(imgb<0.9,0, 1)\n    #plt.imshow(imgb, cmap = 'gray')\n\n    m = tf.keras.metrics.MeanIoU(num_classes=2)\n    m.update_state(imgn, imgb)\n    iou1 = m.result().numpy()\n    plot_images(src_image, gen_image, tar_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iou1 = []\nssim1 = []\nPSNR = []\nfor i in range(len(iou)):\n    iou1.append(float(iou[i]))\n    ssim1.append(float(ssi[i]))\n    PSNR.append(float(psi[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\nplt.plot(iou1)\nplt.ylabel('IOU')\nplt.xlabel('Image id')\nplt.show()\nplt.plot(ssim1)\nplt.ylabel('SSIM')\nplt.xlabel('Image id')\nplt.show()\nplt.plot(PSNR)\nplt.ylabel('PSNR')\nplt.xlabel('Image id')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nprint('mean iou: ', np.mean(iou1))\nprint('mean SSIM: ', np.mean(ssim1))\nprint('mean PSNR: ', np.mean(PSNR))\nprint('mean iou: ', np.std(iou1))\nprint('mean SSIM: ', np.std(ssim1))\nprint('mean PSNR: ', np.std(PSNR))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = (pd.DataFrame([iou1, ssim1, PSNR])).transpose()\ndf.columns = ['iou', 'ssim', 'PSNR']\ndf.to_csv('train.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# final testing images","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom numpy import load\nfrom numpy import vstack\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom numpy.random import randint\nimport tensorflow.keras as tf\n# load and prepare training images\ndef load_real_samples(filename):\n    # load compressed arrays\n    data = load(filename)\n    # unpack arrays\n    X1, X2 = data['arr_0'], data['arr_1']\n    # scale from [0,255] to [-1,1]\n    X1 = ((X1) / 255.0)\n    X2 = ((X2) / 255.0)\n    return [X1, X2]\nssi = []\npsi = []\niou = []\n# plot source, generated and target images\ndef plot_images(src_img, gen_img, tar_img):\n    images = vstack((src_img, gen_img, tar_img))\n    # scale from [-1,1] to [0,1]\n    images = (images + 1) / 2.0\n    titles = ['Source', 'Generated', 'Expected']\n    # plot images row by row\n    #fig = plt.figure(figsize = [8,8])\n    #for i in range(len(images)):\n        # define subplot\n        #ax = pyplot.subplot(1, 3, 1 + i)\n        #plt.figure(figsize = [5,5])\n        # turn off axis\n        #pyplot.axis('off')\n        # plot raw pixel data\n        #ax.imshow(np.squeeze(images[i]).astype(np.float32), cmap = 'gray')\n        # show title\n        #ax.set_title(titles[i])\n    ss = str(float(ssim1))\n    ps = str(float(psnr1))\n    io = str(float(iou1))\n    \n    a =  'SSIM:' ,ss[:5], 'PSNR:' ,  ps[:5], 'IOU=', io[:5]\n    print(a)\n    \n    ssi.append(ss)\n    psi.append(ps)\n    iou.append(io)\n    #fig.suptitle(a)\n    #fig.tight_layout()\n    #fig.subplots_adjust(top= 1.5)\n    #plt.savefig(name, bbox_inches = 'tight', pad_inches = 0)\n    \n    pyplot.show()\n    \nimport tensorflow as tf \n#tf.random.Generator = None  # Patch for a bug\nfrom tensorflow_addons.layers import InstanceNormalization","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[X2, X1] = load_real_samples('../input/finaldata/finaltesting.npz')\n#print('Loaded', X1.shape, X2.shape)\n# load model\n\n#print('Loaded', X1.shape, X2.shape)\n# load model\n\n\nimport numpy as np \nXD = np.arange(0,555-20)\nfor i in range(555-20):\n    print('for image number ', i )\n    name = 'mname'+ '_'+str(i) +'_' + '.png'\n\n    ix = XD[i]\n    ix = np.array([ix])\n    tar_image, src_image   = X1[[ix]], X2[[ix]]\n    # generate image from source\n    gen_image = model.predict(src_image)\n    # plot all three images\n    images = vstack((src_image, gen_image, tar_image))\n    images = (images + 1) / 2.0\n    df = images[1]\n\n    print('RAW image: ', 'Min: %.3f, Max: %.3f' % (df.min(), df.max()))\n    df1 = ((df) / df.max())*255\n    print('After rescaling: Min: %.3f, Max: %.3f' % (df1.min(), df1.max()))\n    dfn = images[2]\n\n    print('RAW image: ', 'Min: %.3f, Max: %.3f' % (dfn.min(), dfn.max()))\n    dfn1 = ((dfn) / dfn.max())*255\n    print('After rescaling: Min: %.3f, Max: %.3f' % (dfn1.min(), dfn1.max()))\n\n    a =tf.convert_to_tensor(df1, tf.uint8)\n    b = tf.convert_to_tensor(dfn1, tf.uint8)\n    ssim1 = tf.image.ssim(a,b, max_val=255, filter_size=11,filter_sigma=1.5, k1=0.01, k2=0.03) \n    psnr1 = tf.image.psnr(a, b, max_val=255)\n    print(float(ssim1))\n    print(float(psnr1))\n    im1 = tf.image.convert_image_dtype(a, tf.float32)\n    im2 = tf.image.convert_image_dtype(b, tf.float32)\n    ssim2 = tf.image.ssim(im1,im2, max_val=1, filter_size=11,\n                          filter_sigma=1.5, k1=0.01, k2=0.03)\n    # IOU calculation \n    a1 = a[:,:,0]\n    img = a1/np.max(a1)\n    imgn = np.where(img<0.9,0, 1)\n\n    #plt.imshow(imgn, cmap = 'gray')\n\n    b1 = b[:,:,0]\n    imgb = b1/np.max(b1)\n    imgb = np.where(imgb<0.9,0, 1)\n    #plt.imshow(imgb, cmap = 'gray')\n\n    m = tf.keras.metrics.MeanIoU(num_classes=2)\n    m.update_state(imgn, imgb)\n    iou1 = m.result().numpy()\n    plot_images(src_image, gen_image, tar_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iou1 = []\nssim1 = []\nPSNR = []\nfor i in range(len(iou)):\n    iou1.append(float(iou[i]))\n    ssim1.append(float(ssi[i]))\n    PSNR.append(float(psi[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nprint('mean iou: ', np.mean(iou1))\nprint('mean SSIM: ', np.mean(ssim1))\nprint('mean PSNR: ', np.mean(PSNR))\nprint('mean iou: ', np.std(iou1))\nprint('mean SSIM: ', np.std(ssim1))\nprint('mean PSNR: ', np.std(PSNR))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\nplt.plot(iou1)\nplt.ylabel('IOU')\nplt.xlabel('Image id')\nplt.show()\nplt.plot(ssim1)\nplt.ylabel('SSIM')\nplt.xlabel('Image id')\nplt.show()\nplt.plot(PSNR)\nplt.ylabel('PSNR')\nplt.xlabel('Image id')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = (pd.DataFrame([iou1, ssim1, PSNR])).transpose()\ndf.columns = ['iou', 'ssim', 'PSNR']\ndf.to_csv('testfinal.csv')","metadata":{},"execution_count":null,"outputs":[]}]}